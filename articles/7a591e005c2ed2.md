---
title: "DynamoDB Streamsによるデータ同期システムの実現"
emoji: "🌊"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AWS", "DynamoDB", "EventBridge", "Terraform"]
published: false
---

## はじめに

この記事は[dipアドベントカレンダー2025](https://qiita.com/advent-calendar/2025/dip-dev) 16日目の投稿になります！

私はスポットバイトルというサービスをドメイン駆動設計を軸にリアーキテクチャするチームに属しています。

現在、モノリシックなシステムからマイクロサービスへのストラングラーフィグパターンによる段階的移行を進めています。
この移行期間中は新旧両方のデータベースにデータを同期する必要があり、その仕組みとして**DynamoDB Streamsを活用したリアルタイム同期**を構築しました。

本記事では、備忘録としてこの同期の仕組みを紹介したいと思います！

- リアーキテクチャの具体的な取り組み内容や背景が気になる方は下記の記事をご覧ください
https://findy-tools.io/articles/dip-feature-article-2025/168

### 対象読者

- DynamoDB Streamsの実践的な活用例を知りたい方
- 新旧システム間のデータ同期方法を検討している方

## システム構成

```
┌─────────────────────────────────────────────────────────────────┐
│ 旧システム（BFF層として残存）                                      │
│ ALB → ECS                                                       │
│ ・一部の処理はまだ自分で実行 → RDB                                 │
│ ・移行済みの処理は新システムに委譲                                  │
└──────────────────────────┬──────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────────┐
│ 新システム                                                       │
│ ALB → API Gateway → Lambda → DynamoDB                           │
└──────────────────────────┬──────────────────────────────────────┘
                           ↓ DynamoDB Streams
┌─────────────────────────────────────────────────────────────────┐
│ データ同期層                                                     │
│ EventBridge Pipes → SQS FIFO → VPC Lambda → RDB                 │
└─────────────────────────────────────────────────────────────────┘
```

旧システムはBFF層として残存し、フロントエンドからのリクエストを受け付けます。移行済みの機能は新システムに委譲するため、フロントエンドには影響がありません。

新システムで更新されたデータは、データ同期層を通じて旧システムのRDBに反映されます。

### なぜこの構成にしたか

ストラングラーフィグパターンで段階的に移行を進めているため、旧システムの一部機能がまだRDBを参照しています。そのため、新システムで処理したデータを旧システムのRDBに書き戻す必要がありました。

他に検討した方式と、採用しなかった理由です。

- **アプリケーションでの二重書き込み**
  - 新システムが旧システムのスキーマに依存してしまう。また、2つのDBへの書き込みをトランザクションとして扱えない
- **バッチ同期**
  - リアルタイム性が求められる今回の要件に合わない

新システムのデータストアには**DynamoDB**を選びました。リクエスト数が少なくPAY_PER_REQUESTでコストを抑えられること、コンテキスト内でテーブル間の連携が不要なこと、Lambdaとの相性が良いことが決め手です。

データ同期には**DynamoDB Streams**を使います。新システムはDynamoDBに書き込むだけでよく、旧システムの存在を意識する必要がありません。同期処理を別コンポーネントに分離できる点も魅力でした。

Streamsの消費には**EventBridge Pipes**を採用しました。Lambdaを書かずに入力トランスフォーマーでデータ変換ができ、フィルタリングも宣言的に記述できます。料金も1万件あたり0.4ドル程度とコスト面でも有利です。

キューには**SQS FIFO**を選択しました。DynamoDB Streams + EventBridge Pipesの段階ではパーティションキー単位で順序が保たれますが、標準キューでは順序が崩れる可能性があります。同一エンティティに対する変更を正しい順序で旧RDBに反映する必要があったため、FIFOキューが必要でした。

また、各層にDead Letter Queue（DLQ）を配置し、処理失敗時にはCloudWatch Alarmで検知して後から調査・再処理できるようにしています。DLQのメッセージはAWSコンソールから手動で再ドライブするか、専用のLambdaで処理キューに戻すことで再処理が可能です。

以降のセクションでは、各層の実装について詳しく説明します。

## DynamoDB Streams

DynamoDB Streamsは、DynamoDBテーブルへの変更をリアルタイムにキャプチャする機能です。テーブルに対してアイテムの作成・更新・削除が行われると、その変更情報がStreamに記録されます。

DynamoDB Streamsの特徴を押さえておきます。

- DynamoDBへの書き込みは自動的にStreamに記録される
- 同一パーティションキー内では変更が発生した順序でイベントが配信される
- イベントは少なくとも1回は配信される（At-least-once）。重複の可能性があるため、消費側で冪等性を担保する必要がある（詳細は後述）
- Streamのデータは24時間保持される

### Transactional Outbox Pattern

分散システムにおいて、「データベースへの書き込み」と「イベントの配信」という2つの操作を確実に実行するのは難しい問題です。Transactional Outbox Patternは、**データベースへの書き込みとイベント保存を同一トランザクションで行う**ことでこの問題を解決します。

DynamoDBの場合、業務データとイベントデータを同一アイテムに保存することで、アトミックな操作を実現できます。書き込みが成功すれば、必ずDynamoDB Streamsにイベントが流れることが保証されます。

```json
{
  "order_id": "ORD-20240101-12345",
  "customer_id": 999,
  "order_details": {
    "items": [...],
    "total_amount": 3000,
    "status": "confirmed"
  },
  "event": {
    "event_id": "uuid-2",
    "event_type": "order.confirmed",
    "payload": { ... }
  }
}
```

アプリケーション側では、ドメインの操作とイベントの保存を一度の書き込みで行います。

```go
// ドメインの操作を実行
order.Confirm(confirmParam)

// 業務データとイベントを同一トランザクションで保存
// DynamoDBの場合、単一アイテムへの書き込みはアトミック
event := order.CreateConfirmedEvent()
repo.SaveWithEvent(ctx, order, event)
```

### Terraform定義例

```hcl
resource "aws_dynamodb_table" "orders" {
  name             = "orders"
  billing_mode     = "PAY_PER_REQUEST"
  hash_key         = "order_id"
  stream_enabled   = true
  stream_view_type = "NEW_IMAGE"

  attribute {
    name = "order_id"
    type = "S"
  }
}
```

#### 設定のポイント

- `stream_enabled = true`でDynamoDB Streamsを有効化
- `stream_view_type = "NEW_IMAGE"`で変更後のアイテム全体をStreamに記録

## EventBridge Pipes

EventBridge Pipesは、AWSのイベントソースとターゲットを接続するサービスです。ソースからイベントを受け取り、フィルタリングや変換を行った上でターゲットに配信できます。DynamoDB固有の型情報を含む複雑な構造も、入力トランスフォーマーでコードを書かずに変換できるのが便利です。

### 入力トランスフォーマーによるデータ変換

DynamoDB Streamsの出力:

```json
{
  "dynamodb": {
    "Keys": {
      "order_id": { "S": "ORD-20240101-12345" }
    },
    "NewImage": {
      "event": {
        "M": {
          "event_type": { "S": "order.confirmed" }
        }
      },
      "customer_id": { "N": "999" },
      "order_details": {
        "M": {
          "total_amount": { "N": "3000" },
          "status": { "S": "confirmed" }
        }
      }
    }
  }
}
```

`M`はMap型、`S`はString型、`N`はNumber型を表すDynamoDB固有の型情報です。

変換後:

```json
{
  "eventType": "order.confirmed",
  "orderID": "ORD-20240101-12345",
  "customerID": "999",
  "orderDetails": {
    "totalAmount": "3000",
    "status": "confirmed"
  }
}
```

型情報を除去してシンプルにしています。

### Terraform定義例

IAMロールの定義は省略しています。

```hcl
resource "aws_pipes_pipe" "orders" {
  name     = "orders-pipe"
  role_arn = aws_iam_role.pipes_execution_role.arn
  source   = aws_dynamodb_table.orders.stream_arn
  target   = aws_sqs_queue.orders_fifo.arn

  source_parameters {
    dynamodb_stream_parameters {
      batch_size                 = 10
      starting_position          = "TRIM_HORIZON"
      maximum_retry_attempts     = 3
      maximum_record_age_in_seconds = 300

      dead_letter_config {
        arn = aws_sqs_queue.pipes_dlq.arn
      }
    }

    filter_criteria {
      filter {
        pattern = jsonencode({
          dynamodb = {
            NewImage = {
              event = {
                M = {
                  event_id = {
                    S = [{ exists = true }]
                  }
                }
              }
            }
          }
        })
      }
    }
  }

  target_parameters {
    sqs_queue_parameters {
      message_group_id = "$.dynamodb.Keys.order_id.S"
    }

    input_template = <<-JSON
      {
        "eventType": <$.dynamodb.NewImage.event.M.event_type.S>,
        "orderID": <$.dynamodb.Keys.order_id.S>,
        "customerID": "<$.dynamodb.NewImage.customer_id.N>",
        "orderDetails": {
          "totalAmount": "<$.dynamodb.NewImage.order_details.M.total_amount.N>",
          "status": <$.dynamodb.NewImage.order_details.M.status.S>
        }
      }
    JSON
  }
}

resource "aws_sqs_queue" "pipes_dlq" {
  name = "orders-pipes-dlq"
}
```

#### 設定のポイント

- `starting_position = "TRIM_HORIZON"`でStreamに残っている最も古いレコードから処理を開始。Pipes作成前に発生した変更も漏れなく処理できる
- `filter_criteria`で`event_id`が存在するレコードのみを処理対象にフィルタリング
- `message_group_id`にパーティションキー（`order_id`）を指定し、同じ注文に対する変更を順序通りに処理（異なる注文間では並列処理が可能）
- `input_template`はJSONPath式を使ってデータを変換。数値型（`N`）の値を取得する場合は、クォートで囲んで文字列として渡す

## SQS FIFO

SQS FIFOは、メッセージの順序を保証し、重複配信を防ぐキューサービスです。

FIFOキューのメリットは順序保証だけではありません。

- **メッセージ保持期間**: SQSは最大14日間保持できるため、DynamoDB Streamsの24時間という制限よりも長い猶予が得られる
- **重複排除**: `content_based_deduplication`によりメッセージの重複配信を防げる

### Terraform定義例

```hcl
resource "aws_sqs_queue" "orders_fifo" {
  name                        = "orders-sync.fifo"
  fifo_queue                  = true
  content_based_deduplication = true
  visibility_timeout_seconds  = 30

  redrive_policy = jsonencode({
    deadLetterTargetArn = aws_sqs_queue.orders_dlq.arn
    maxReceiveCount     = 3
  })
}

resource "aws_sqs_queue" "orders_dlq" {
  name                      = "orders-sync-dlq.fifo"
  fifo_queue                = true
  message_retention_seconds = 1209600  # 14日間
}
```

#### 設定のポイント

- `content_based_deduplication = true`でメッセージ本文に基づく重複排除を有効化
- `message_retention_seconds = 1209600`でDLQのメッセージを14日間保持
- `maxReceiveCount = 3`で、3回処理に失敗したメッセージをDLQに移動

## Lambda

SQS FIFOのメッセージを処理し、旧RDBにデータを同期するLambdaです。

### Partial Batch Response

SQSトリガーのLambdaでは、複数のメッセージをバッチで受け取って処理します。バッチ内の一部のメッセージだけが失敗した場合、デフォルトではバッチ全体が再処理されてしまいます。

`ReportBatchItemFailures`を有効にすると、失敗したメッセージのみを報告でき、成功したメッセージは再処理されません。

```hcl
resource "aws_lambda_event_source_mapping" "sqs_trigger" {
  event_source_arn                   = aws_sqs_queue.orders_fifo.arn
  function_name                      = aws_lambda_function.sync_to_rdb.arn
  batch_size                         = 10
  maximum_batching_window_in_seconds = 5

  scaling_config {
    maximum_concurrency = 2
  }

  function_response_types = ["ReportBatchItemFailures"]
}
```

Lambda関数では、失敗したメッセージのIDを`batchItemFailures`として返します。

```go
type SQSBatchResponse struct {
    BatchItemFailures []BatchItemFailure `json:"batchItemFailures"`
}

type BatchItemFailure struct {
    ItemIdentifier string `json:"itemIdentifier"`
}

func Handler(ctx context.Context, event events.SQSEvent) (SQSBatchResponse, error) {
    var failures []BatchItemFailure

    for _, record := range event.Records {
        if err := processMessage(ctx, record); err != nil {
            failures = append(failures, BatchItemFailure{
                ItemIdentifier: record.MessageId,
            })
        }
    }

    return SQSBatchResponse{BatchItemFailures: failures}, nil
}
```

### 冪等性の保証

Lambdaの処理が成功しても、SQSへの応答がタイムアウトすると同じメッセージが再配信される可能性があります。そのため、処理の冪等性を担保しておくことが重要です。

```go
func ProcessOrderEvent(ctx context.Context, payload *MessagePayload) error {
    tx, err := db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer func() {
        if err != nil {
            _ = tx.Rollback()
        }
    }()

    switch payload.EventType {
    case "order.created":
        // INSERTはユニーク制約で重複を防ぐ
        err = insertOrder(ctx, tx, payload)
    case "order.confirmed":
        // UPDATEは影響行数をチェックして冪等性を担保
        err = updateOrderStatus(ctx, tx, payload)
    case "order.shipped":
        err = updateOrderShipping(ctx, tx, payload)
    default:
        return nil
    }

    if err != nil {
        return err
    }

    return tx.Commit()
}
```

UPDATEの場合は影響を受けた行数をチェックし、INSERTの場合はユニーク制約やイベントIDによる重複チェックを行うことで冪等性を担保します。

## まとめ

本記事では、DynamoDB Streamsを活用した新旧システム間のデータ同期の仕組みを紹介しました。

実際に構築してみて、以下の点がメリットだと感じています。

- 新システムは旧システムの存在を意識せずにDynamoDBに書き込むだけでよく、疎結合を保てる
- Transactional Outbox Patternにより、業務データとイベントをアトミックに保存できる
- 即時整合性ではなく結果整合性を受け入れることで、シンプルな非同期連携を実現できた
- データ同期層は移行期間限定の仕組みとして独立しており、移行完了後は削除するだけ

注意点として、同期には数秒の遅延があるため、強い整合性が必要な場合は[Sagaパターン](https://docs.aws.amazon.com/ja_jp/prescriptive-guidance/latest/modernization-data-persistence/saga-pattern.html)などを検討してください。

## 参考資料

- [DynamoDB Streams の変更データキャプチャ](https://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/Streams.html)
- [Amazon EventBridge Pipes](https://docs.aws.amazon.com/ja_jp/eventbridge/latest/userguide/eb-pipes.html)
- [EventBridge Pipes のソースとしての DynamoDB ストリーム](https://docs.aws.amazon.com/ja_jp/eventbridge/latest/userguide/eb-pipes-dynamodb.html)
- [Transactional Outbox パターン](https://docs.aws.amazon.com/ja_jp/prescriptive-guidance/latest/cloud-design-patterns/transactional-outbox.html)
- [ストラングラーフィグパターン](https://docs.aws.amazon.com/ja_jp/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html)
